\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\PassOptionsToPackage{hyphens}{url} % url is loaded by hyperref
\usepackage[unicode=true]{hyperref}
\hypersetup{
            pdftitle={My Project},
            pdfauthor={Bill Last Updated:},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{long table}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\title{My Project}
\author{Bill Last Updated:}
\date{23 January, 2020}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter*{Preface: Motivation}\label{my-section}
\addcontentsline{toc}{chapter}{Preface: Motivation}

This is my MS project (in progress). While I have tried my best,
probably there are still some typos and errors. Please feel free to let
me know in case you find one. Thank you!

\chapter{Practice: Learning on the Battle
Field}\label{practice-learning-on-the-battle-field}

\section{R code}\label{r-code}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#https://fivethirtyeight.com/contributors/josh-hermsmeyer/}
\CommentTok{# https://github.com/ryurko/nflscrapR-data/blob/master/legacy_data/README.md}

\CommentTok{#mydata1 = read.csv('plays.txt')}
\CommentTok{#unique(mydata1$gameId)}

\CommentTok{#unique(mydata1$PassLength)}
\CommentTok{#table(mydata1$PassLength)}
\CommentTok{#table(mydata1$PassResult)}
\CommentTok{#table(mydata1$numberOfPassRushers)}


\NormalTok{##mydata3 = read.csv(url('https://raw.githubusercontent.com/ryurko/nflscrapR-data/master/legacy_data/season_play_by_play/pbp_2017.csv'))}
\NormalTok{##write.csv(mydata3,'2017playbyplay.csv')}

\NormalTok{mydata3<-}\KeywordTok{read.csv}\NormalTok{(}\StringTok{'2017playbyplay.csv'}\NormalTok{)}
\KeywordTok{nrow}\NormalTok{(mydata3)}
\KeywordTok{table}\NormalTok{(mydata3}\OperatorTok{$}\NormalTok{Passer)}
\KeywordTok{table}\NormalTok{(mydata3}\OperatorTok{$}\NormalTok{PlayType)}

\CommentTok{#mydata5<-mydata3[!duplicated(mydata3[,c('GameID','Passer')]),]}
\CommentTok{#unique(mydata3$GameID)}
\NormalTok{mydata6<-}\KeywordTok{subset}\NormalTok{(mydata3,down}\OperatorTok{==}\DecValTok{1}\NormalTok{)}


\NormalTok{mydata7<-}\KeywordTok{subset}\NormalTok{(mydata6,PlayType}\OperatorTok{==}\StringTok{'Pass'}\OperatorTok{|}\NormalTok{PlayType}\OperatorTok{==}\StringTok{'Run'}\NormalTok{)}
\CommentTok{#table(mydata7$PlayType)}
\CommentTok{#table(droplevels(mydata7$PlayType))}

\NormalTok{mydata7}\OperatorTok{$}\NormalTok{PlayType<-}\KeywordTok{droplevels}\NormalTok{(mydata7}\OperatorTok{$}\NormalTok{PlayType)}
\KeywordTok{table}\NormalTok{(mydata7}\OperatorTok{$}\NormalTok{PlayType)}

\CommentTok{#http://rstudio-pubs-static.s3.amazonaws.com/6975_c4943349b6174f448104a5513fed59a9.html}
\KeywordTok{source}\NormalTok{(}\StringTok{"http://pcwww.liv.ac.uk/~william/R/crosstab.r"}\NormalTok{)}
\NormalTok{mydata8<-mydata7[,}\KeywordTok{c}\NormalTok{(}\StringTok{'Passer'}\NormalTok{,}\StringTok{'PlayType'}\NormalTok{,}\StringTok{'GameID'}\NormalTok{,}\StringTok{'posteam'}\NormalTok{,}\StringTok{'DefensiveTeam'}\NormalTok{,}\StringTok{'Yards.Gained'}\NormalTok{,}\StringTok{'FirstDown'}\NormalTok{,}\StringTok{'TimeSecs'}\NormalTok{)]}
\CommentTok{#results<-crosstab(mydata8, row.vars = "GameID", col.vars = "PlayType", type = "r")}
\CommentTok{#p1<-results$crosstab}
\CommentTok{#hist(p1[,1],20)}



\KeywordTok{library}\NormalTok{(plyr)}
\NormalTok{count_vector<-}\KeywordTok{count}\NormalTok{(mydata8, }\StringTok{"GameID"}\NormalTok{)}

\NormalTok{l_new<-}\KeywordTok{length}\NormalTok{(count_vector}\OperatorTok{$}\NormalTok{freq)}
\NormalTok{time<-}\KeywordTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{l_new)}
\NormalTok{\{time<-}\KeywordTok{append}\NormalTok{(time,}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{count_vector}\OperatorTok{$}\NormalTok{freq[i]))\}}
\KeywordTok{nrow}\NormalTok{(time)}
\NormalTok{mydata8}\OperatorTok{$}\NormalTok{time<-time}
\NormalTok{mydata8}\OperatorTok{$}\NormalTok{play_new<-}\KeywordTok{ifelse}\NormalTok{(mydata8}\OperatorTok{$}\NormalTok{PlayType}\OperatorTok{==}\StringTok{'Pass'}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)}

\NormalTok{n_counting<-}\DecValTok{0}  \CommentTok{# help counting the number of pairs}

\NormalTok{## The following code collects all the rows of each pair. However, it is difficult to analyze data}
\CommentTok{# in such a format. }

\CommentTok{#empty_df = mydata8[FALSE,]}
\CommentTok{#for (i in 1:l_new) # level of different game}
\CommentTok{#\{}
\CommentTok{#   for(j in 1:((count_vector$freq[i])-1)) # within the same game}
\CommentTok{#   \{}
\CommentTok{#      if(i==1)}
\CommentTok{#      \{row_id<-j\}}
\CommentTok{#      else \{row_id<-sum(count_vector$freq[1:(i-1)])+j\}}
\CommentTok{#}
\CommentTok{#      #print(row_id)}
\CommentTok{#      if(as.character(mydata8[row_id,]$posteam)!=as.character(mydata8[row_id+1,]$posteam))}
\CommentTok{#      \{}
\CommentTok{#        print("not same team")}
\CommentTok{#        if (nrow(empty_df)==0)}
\CommentTok{#           \{empty_df<-mydata8[row_id:(row_id+1),]\}}
\CommentTok{#        else}
\CommentTok{#           \{}
\CommentTok{#             if(row.names(mydata8[row_id,])!=row.names(tail(empty_df,1)))}
\CommentTok{#               \{empty_df<-rbind(empty_df,mydata8[row_id,])\}}
\CommentTok{#             empty_df<-rbind(empty_df,mydata8[row_id+1,])}
\CommentTok{#           \}}
\CommentTok{#       n_counting<-n_counting+1}
\CommentTok{#      \}}
\CommentTok{#   \}}
\CommentTok{#\}}


\CommentTok{# The following code only collects the second row of the pair, but adds data of }
\NormalTok{### PT_L: type of play in the last first down from the other team}
\NormalTok{### TG_L: Yards.Gained in the last play}
\NormalTok{### FirstDown: did they get first down or not. Note that, if yes, it means it was a fumble.}

\NormalTok{PT_L=}\StringTok{"Pass"}
\NormalTok{TG_L=}\DecValTok{0}
\NormalTok{FD_L=}\DecValTok{0}

\NormalTok{pari_data=}\StringTok{ }\NormalTok{mydata8[}\DecValTok{1}\NormalTok{,]}
\NormalTok{pari_data<-}\KeywordTok{cbind}\NormalTok{(pari_data,PT_L,TG_L,FD_L)}
\NormalTok{pari_data<-pari_data[}\OtherTok{FALSE}\NormalTok{,]}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{l_new) }\CommentTok{# level of different game}
\NormalTok{\{}
  \ControlFlowTok{for}\NormalTok{(j }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{((count_vector}\OperatorTok{$}\NormalTok{freq[i])}\OperatorTok{-}\DecValTok{1}\NormalTok{)) }\CommentTok{# within the same game}
\NormalTok{  \{}

    \ControlFlowTok{if}\NormalTok{(i}\OperatorTok{==}\DecValTok{1}\NormalTok{)}
\NormalTok{    \{row_id<-j\}}
    \ControlFlowTok{else}\NormalTok{ \{row_id<-}\KeywordTok{sum}\NormalTok{(count_vector}\OperatorTok{$}\NormalTok{freq[}\DecValTok{1}\OperatorTok{:}\NormalTok{(i}\OperatorTok{-}\DecValTok{1}\NormalTok{)])}\OperatorTok{+}\NormalTok{j\}}

    \KeywordTok{print}\NormalTok{(row_id)}
    \ControlFlowTok{if}\NormalTok{(}\KeywordTok{as.character}\NormalTok{(mydata8[row_id,]}\OperatorTok{$}\NormalTok{posteam)}\OperatorTok{!=}\KeywordTok{as.character}\NormalTok{(mydata8[row_id}\OperatorTok{+}\DecValTok{1}\NormalTok{,]}\OperatorTok{$}\NormalTok{posteam))}
\NormalTok{    \{}
      \KeywordTok{print}\NormalTok{(}\StringTok{"not same team"}\NormalTok{)}
\NormalTok{      PT_L<-}\KeywordTok{as.character}\NormalTok{(mydata8[row_id,]}\OperatorTok{$}\NormalTok{PlayType)}
\NormalTok{      TG_L<-mydata8[row_id,]}\OperatorTok{$}\NormalTok{Yards.Gained}
\NormalTok{      FD_L<-mydata8[row_id,]}\OperatorTok{$}\NormalTok{FirstDown}

\NormalTok{      new_row<-}\KeywordTok{cbind}\NormalTok{(mydata8[(row_id}\OperatorTok{+}\DecValTok{1}\NormalTok{),],PT_L,TG_L,FD_L)}
\NormalTok{      pari_data<-}\KeywordTok{rbind}\NormalTok{(pari_data,new_row)}
\NormalTok{     \}}

\NormalTok{      n_counting<-n_counting}\OperatorTok{+}\DecValTok{1}
\NormalTok{  \}}
\NormalTok{\}}

\NormalTok{pari_data}\OperatorTok{$}\NormalTok{same<-}\KeywordTok{ifelse}\NormalTok{(pari_data}\OperatorTok{$}\NormalTok{PlayType}\OperatorTok{==}\NormalTok{pari_data}\OperatorTok{$}\NormalTok{PT_L,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)}

\CommentTok{#write.csv(pari_data,'pari_data.csv')}

\KeywordTok{write.table}\NormalTok{(pari_data, }\DataTypeTok{file =} \StringTok{"pari_data.csv"}\NormalTok{,}\DataTypeTok{row.names=}\OtherTok{FALSE}\NormalTok{,}\DataTypeTok{na =} \StringTok{""}\NormalTok{, }\DataTypeTok{sep=}\StringTok{","}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Remarks}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  mylogit1: in general, a team has a different play in their first down,
  compared to the other team in the last first down.
\item
  mylogit2: If the defence team passed in the last first down, the
  offence team is less likely to use pass. If the defence team gained
  more yards, the offence team is more likely to pass in the next first
  down. If the defence team fumbled, it will reduce the chance the
  offence team to do the pass.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pari_data2<-}\KeywordTok{read.csv}\NormalTok{(}\StringTok{'pari_data.csv'}\NormalTok{)}

\NormalTok{mylogit1 =}\StringTok{ }\KeywordTok{glm}\NormalTok{(same}\OperatorTok{~}\DecValTok{1}\NormalTok{, }\DataTypeTok{family=}\NormalTok{binomial, }\DataTypeTok{data=}\NormalTok{pari_data2)}
\KeywordTok{summary}\NormalTok{(mylogit1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = same ~ 1, family = binomial, data = pari_data2)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.117  -1.117  -1.117   1.239   1.239  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -0.14395    0.02809  -5.124    3e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 7035.5  on 5093  degrees of freedom
## Residual deviance: 7035.5  on 5093  degrees of freedom
## AIC: 7037.5
## 
## Number of Fisher Scoring iterations: 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mylogit2 =}\StringTok{ }\KeywordTok{glm}\NormalTok{(play_new}\OperatorTok{~}\NormalTok{same}\OperatorTok{+}\NormalTok{TG_L}\OperatorTok{+}\NormalTok{FD_L, }\DataTypeTok{family=}\NormalTok{binomial, }\DataTypeTok{data=}\NormalTok{pari_data2)}
\KeywordTok{summary}\NormalTok{(mylogit2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = play_new ~ same + TG_L + FD_L, family = binomial, 
##     data = pari_data2)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.6114  -0.9783  -0.9382   1.0995   1.5672  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  0.175629   0.040712   4.314  1.6e-05 ***
## same        -0.757822   0.057618 -13.152  < 2e-16 ***
## TG_L         0.010439   0.003873   2.695  0.00704 ** 
## FD_L        -0.268115   0.148835  -1.801  0.07164 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 7034.3  on 5093  degrees of freedom
## Residual deviance: 6850.1  on 5090  degrees of freedom
## AIC: 6858.1
## 
## Number of Fisher Scoring iterations: 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lme4)}
\NormalTok{mylogit3 =}\StringTok{ }\KeywordTok{glmer}\NormalTok{(same}\OperatorTok{~}\NormalTok{play_new}\OperatorTok{+}\NormalTok{TG_L}\OperatorTok{+}\NormalTok{FD_L}\OperatorTok{+}\NormalTok{(}\DecValTok{1}\OperatorTok{|}\NormalTok{GameID), }\DataTypeTok{family=} \KeywordTok{binomial}\NormalTok{(}\StringTok{"logit"}\NormalTok{), }\DataTypeTok{data=}\NormalTok{pari_data2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## boundary (singular) fit: see ?isSingular
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(mylogit3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: same ~ play_new + TG_L + FD_L + (1 | GameID)
##    Data: pari_data2
## 
##      AIC      BIC   logLik deviance df.resid 
##   6862.4   6895.1  -3426.2   6852.4     5089 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.3918 -0.7763 -0.7532  0.9061  1.6255 
## 
## Random effects:
##  Groups Name        Variance  Std.Dev. 
##  GameID (Intercept) 1.562e-15 3.953e-08
## Number of obs: 5094, groups:  GameID, 256
## 
## Fixed effects:
##              Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  0.197140   0.040513   4.866 1.14e-06 ***
## play_new    -0.757838   0.057619 -13.153  < 2e-16 ***
## TG_L         0.006027   0.003824   1.576  0.11502    
## FD_L        -0.392792   0.150715  -2.606  0.00916 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Correlation of Fixed Effects:
##          (Intr) ply_nw TG_L  
## play_new -0.627              
## TG_L     -0.270 -0.043       
## FD_L     -0.147  0.031 -0.041
## convergence code: 0
## boundary (singular) fit: see ?isSingular
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Bill_1<- bild(play_new ~ TG_L+FD_L, data = mydata8, id="GameID",start = NULL, dependence = "MC1R")}
\CommentTok{#summary(Bill_1)}

\CommentTok{#locust2 <- bild(as.factor(PlayType) ~ time + I(time^2), data = mydata8,id="GameID",start = NULL, dependence = "MC2")}
\end{Highlighting}
\end{Shaded}

\section{References}\label{references}

\url{https://arxiv.org/pdf/1403.7993.pdf}

\url{http://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter11.pdf}

\url{https://rpubs.com/JanpuHou/326048}

\chapter{Project Draft}\label{project-draft}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata3<-}\KeywordTok{read.csv}\NormalTok{(}\StringTok{'Schnibbe 1502 Binary Data.csv'}\NormalTok{)}
\KeywordTok{head}\NormalTok{(mydata3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   X0
## 1  0
## 2  1
## 3  0
## 4  0
## 5  1
## 6  0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{NO_new<-}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{222}\NormalTok{)}
\NormalTok{mydata4<-}\KeywordTok{cbind}\NormalTok{(mydata3,NO_new)}
\KeywordTok{head}\NormalTok{(mydata4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   X0 NO_new
## 1  0      1
## 2  1      2
## 3  0      3
## 4  0      4
## 5  1      5
## 6  0      6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a1 =}\StringTok{ }\KeywordTok{glmer}\NormalTok{(X0 }\OperatorTok{~}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1}\OperatorTok{|}\NormalTok{NO_new), }\DataTypeTok{data =}\NormalTok{ mydata4,}\DataTypeTok{family=}\NormalTok{binomial)}
\KeywordTok{summary}\NormalTok{(a1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: X0 ~ 1 + (1 | NO_new)
##    Data: mydata4
## 
##      AIC      BIC   logLik deviance df.resid 
##    243.3    250.1   -119.6    239.3      220 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -0.5461 -0.5461 -0.5461 -0.5461  1.8311 
## 
## Random effects:
##  Groups Name        Variance  Std.Dev.
##  NO_new (Intercept) 1.246e-07 0.000353
## Number of obs: 222, groups:  NO_new, 222
## 
## Fixed effects:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  -1.2098     0.1603  -7.549 4.38e-14 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a2 =}\StringTok{ }\KeywordTok{glm}\NormalTok{(X0 }\OperatorTok{~}\StringTok{ }\DecValTok{1}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ mydata4,}\DataTypeTok{family=}\NormalTok{binomial)}
\KeywordTok{summary}\NormalTok{(a2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = X0 ~ 1, family = binomial, data = mydata4)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.7225  -0.7225  -0.7225  -0.7225   1.7151  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  -1.2098     0.1595  -7.583 3.38e-14 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 239.29  on 221  degrees of freedom
## Residual deviance: 239.29  on 221  degrees of freedom
## AIC: 241.29
## 
## Number of Fisher Scoring iterations: 4
\end{verbatim}

\section{Background}\label{background}

The following code is from this website:
\url{http://www.biostat.umn.edu/~baolin/teaching/probmods/GLMM_mcmc.html}.
I will remove it on this page after I complete my practice and learning.

In this example, it simulates a longitudinal data with 4 variables for
each of 1000 separate individuals. Specifically, there are three
continuous covariates (varying over time) and one ordinal covariate
(constant over time). We will consider a random intercept model (mean
zero and variance 100), and fit the data with glmer() from lme4 R
package.

The R code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n =}\StringTok{ }\DecValTok{1000}\NormalTok{; p =}\StringTok{ }\DecValTok{3}\NormalTok{; K =}\StringTok{ }\DecValTok{4}\NormalTok{; sig =}\StringTok{ }\DecValTok{10}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\NormalTok{## time varying covariates}
\NormalTok{Xl =}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{'list'}\NormalTok{, K)}
\CommentTok{# 4 list, each 1000 individuals}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{K) Xl[[i]] =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(n}\OperatorTok{*}\NormalTok{p), n,p)}

\NormalTok{## constant covariate}
\NormalTok{Z =}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DecValTok{2}\NormalTok{,}\FloatTok{0.2}\NormalTok{)}

\NormalTok{## random effects}
\CommentTok{#just 1000 random numubers?}
\NormalTok{U =}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(n)}\OperatorTok{*}\NormalTok{sig}

\NormalTok{## fixed effects}
\CommentTok{# It ends a 1000*4 matrix}
\NormalTok{etaX =}\StringTok{ }\KeywordTok{sapply}\NormalTok{(Xl, rowSums)}

\NormalTok{## random errors}
\NormalTok{eps =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(n}\OperatorTok{*}\NormalTok{K), n,K)}

\NormalTok{## logit model}
\NormalTok{eta =}\StringTok{ }\NormalTok{etaX }\OperatorTok{+}\StringTok{ }\NormalTok{U }\OperatorTok{+}\StringTok{ }\NormalTok{eps}
\CommentTok{# calculate probability}
\NormalTok{prb =}\StringTok{ }\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{eta))}
\NormalTok{D =}\StringTok{ }\DecValTok{1}\OperatorTok{*}\NormalTok{(}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{runif}\NormalTok{(n}\OperatorTok{*}\NormalTok{K),n,K)}\OperatorTok{<}\NormalTok{prb) }\CommentTok{# comparing it to prb, and change to 1 and 0; 1000*4}
\CommentTok{# Select the first list from "Xl", and then add other 3 lists--> 4000 * 3}
\NormalTok{Xs =}\StringTok{ }\NormalTok{Xl[[}\DecValTok{1}\NormalTok{]]}
\ControlFlowTok{for}\NormalTok{(k }\ControlFlowTok{in} \DecValTok{2}\OperatorTok{:}\NormalTok{K) Xs =}\StringTok{ }\KeywordTok{rbind}\NormalTok{(Xs, Xl[[k]])}

\NormalTok{## GLMM model}
\KeywordTok{library}\NormalTok{(lme4)}
\NormalTok{sid =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n, K) }\CommentTok{# a vector of 1-1000, 4 repetitions}
\NormalTok{## model fit with GLMMM (default to Laplace approximation)}
\CommentTok{# subjects as the random effect}
\NormalTok{a1 =}\StringTok{ }\KeywordTok{glmer}\NormalTok{(}\KeywordTok{c}\NormalTok{(D) }\OperatorTok{~}\StringTok{ }\NormalTok{Xs }\OperatorTok{+}\StringTok{ }\NormalTok{Z[sid] }\OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1}\OperatorTok{|}\NormalTok{sid), }\DataTypeTok{family=}\NormalTok{binomial)}

\NormalTok{a1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: c(D) ~ Xs + Z[sid] + (1 | sid)
##       AIC       BIC    logLik  deviance  df.resid 
##  3213.666  3251.430 -1600.833  3201.666      3994 
## Random effects:
##  Groups Name        Std.Dev.
##  sid    (Intercept) 5.816   
## Number of obs: 4000, groups:  sid, 1000
## Fixed Effects:
## (Intercept)          Xs1          Xs2          Xs3       Z[sid]  
##      0.1537       0.6650       0.6429       0.6074       0.0199
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## MH sampling of random effects | data}
\NormalTok{## logit\textbackslash{}Pr(D_i|eta_i,U) = eta_i+U; U \textbackslash{}sim N(0,Vu)}
\NormalTok{## proposal dist: N(Uc,Vc)}

\NormalTok{U.mh <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(Di,eta, Vu, Uc,Vc, }\DataTypeTok{B=}\DecValTok{100}\NormalTok{)\{}
\NormalTok{  ub =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, B)}
\NormalTok{  ub[}\DecValTok{1}\NormalTok{] =}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\KeywordTok{sqrt}\NormalTok{(Vc)}\OperatorTok{+}\NormalTok{Uc }\CommentTok{# random starting value}
\NormalTok{  prb =}\StringTok{ }\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{eta}\OperatorTok{-}\NormalTok{ub[}\DecValTok{1}\NormalTok{]))}
\NormalTok{  llk0 =}\StringTok{ }\KeywordTok{dnorm}\NormalTok{(ub[}\DecValTok{1}\NormalTok{],}\DataTypeTok{sd=}\KeywordTok{sqrt}\NormalTok{(Vu), }\DataTypeTok{log=}\OtherTok{TRUE}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{log}\NormalTok{(Di}\OperatorTok{*}\NormalTok{prb}\OperatorTok{+}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{Di)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{prb))) }\OperatorTok{-}\StringTok{ }\KeywordTok{dnorm}\NormalTok{(ub[}\DecValTok{1}\NormalTok{],Uc,}\KeywordTok{sqrt}\NormalTok{(Vc), }\DataTypeTok{log=}\OtherTok{TRUE}\NormalTok{) }\CommentTok{# likelihood function? }
  \ControlFlowTok{for}\NormalTok{(k }\ControlFlowTok{in} \DecValTok{2}\OperatorTok{:}\NormalTok{B)\{}
\NormalTok{    ub[k] =}\StringTok{ }\NormalTok{ub[k}\OperatorTok{-}\DecValTok{1}\NormalTok{]}
\NormalTok{    uk =}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\KeywordTok{sqrt}\NormalTok{(Vc)}\OperatorTok{+}\NormalTok{Uc}
\NormalTok{    prb =}\StringTok{ }\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{eta}\OperatorTok{-}\NormalTok{uk))}
\NormalTok{    llk1 =}\StringTok{ }\KeywordTok{dnorm}\NormalTok{(uk,}\DataTypeTok{sd=}\KeywordTok{sqrt}\NormalTok{(Vu), }\DataTypeTok{log=}\OtherTok{TRUE}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{log}\NormalTok{(Di}\OperatorTok{*}\NormalTok{prb}\OperatorTok{+}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{Di)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{prb))) }\OperatorTok{-}\StringTok{ }\KeywordTok{dnorm}\NormalTok{(uk,Uc,}\KeywordTok{sqrt}\NormalTok{(Vc), }\DataTypeTok{log=}\OtherTok{TRUE}\NormalTok{)}
\NormalTok{    alpha =}\StringTok{ }\KeywordTok{exp}\NormalTok{( llk1 }\OperatorTok{-}\StringTok{ }\NormalTok{llk0  )}
    \ControlFlowTok{if}\NormalTok{(alpha}\OperatorTok{>=}\DecValTok{1}\NormalTok{)\{}
\NormalTok{      ub[k] =}\StringTok{ }\NormalTok{uk}
\NormalTok{      llk0 =}\StringTok{ }\NormalTok{llk1}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{\{}
\NormalTok{      aa =}\StringTok{ }\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{)}
      \ControlFlowTok{if}\NormalTok{(aa}\OperatorTok{<}\NormalTok{alpha)\{}
\NormalTok{        ub[k] =}\StringTok{ }\NormalTok{uk}
\NormalTok{        llk0 =}\StringTok{ }\NormalTok{llk1}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
  \KeywordTok{return}\NormalTok{(ub)}
\NormalTok{\}}

\KeywordTok{library}\NormalTok{(numDeriv)}
\NormalTok{UV.est <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(Di,eta,Vu,Uc)\{}
\NormalTok{  llk0 =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(xpar)\{}
\NormalTok{    Uc =}\StringTok{ }\NormalTok{xpar}
\NormalTok{    prb =}\StringTok{ }\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{eta}\OperatorTok{-}\NormalTok{Uc))}
\NormalTok{    res =}\StringTok{ }\KeywordTok{dnorm}\NormalTok{(Uc,}\DataTypeTok{sd=}\KeywordTok{sqrt}\NormalTok{(Vu), }\DataTypeTok{log=}\OtherTok{TRUE}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{log}\NormalTok{(Di}\OperatorTok{*}\NormalTok{prb}\OperatorTok{+}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{Di)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{prb)))}
    \OperatorTok{-}\NormalTok{res}
\NormalTok{  \}}
\NormalTok{  tmp =}\StringTok{ }\KeywordTok{try}\NormalTok{(}\KeywordTok{optim}\NormalTok{(Uc, llk0, }\DataTypeTok{method=}\StringTok{'Brent'}\NormalTok{, }\DataTypeTok{lower=}\NormalTok{Uc}\OperatorTok{-}\DecValTok{10}\NormalTok{,}\DataTypeTok{upper=}\NormalTok{Uc}\OperatorTok{+}\DecValTok{10}\NormalTok{) )}
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{class}\NormalTok{(tmp)}\OperatorTok{==}\StringTok{'try-error'}\NormalTok{) tmp =}\StringTok{ }\KeywordTok{optim}\NormalTok{(Uc, llk0)}
\NormalTok{  Uc =}\StringTok{ }\NormalTok{tmp}\OperatorTok{$}\NormalTok{par}
\NormalTok{  Vc =}\StringTok{ }\DecValTok{1}\OperatorTok{/}\KeywordTok{hessian}\NormalTok{(llk0, Uc)}
  \KeywordTok{c}\NormalTok{(Uc,Vc)}
\NormalTok{\}}
\NormalTok{UV.mh <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(Vu,beta,Uc, D,X,subj)\{}
\NormalTok{  ## Cov matrix}
\NormalTok{  sid =}\StringTok{ }\KeywordTok{unique}\NormalTok{(subj);  n =}\StringTok{ }\KeywordTok{length}\NormalTok{(sid)}
\NormalTok{  Uc =}\StringTok{ }\NormalTok{Vc =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,n)}
  \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n)\{}
\NormalTok{    ij =}\StringTok{ }\KeywordTok{which}\NormalTok{(subj}\OperatorTok{==}\NormalTok{sid[i]);  ni =}\StringTok{ }\KeywordTok{length}\NormalTok{(ij)}
\NormalTok{    Xi =}\StringTok{ }\NormalTok{X[ij,,drop=}\OtherTok{FALSE}\NormalTok{]}
\NormalTok{    eta =}\StringTok{ }\NormalTok{Xi}\OperatorTok{%*%}\NormalTok{beta}
\NormalTok{    zi =}\StringTok{ }\KeywordTok{UV.est}\NormalTok{(D[ij],eta,Vu,Uc[i])}
\NormalTok{    Uc[i] =}\StringTok{ }\NormalTok{zi[}\DecValTok{1}\NormalTok{]; Vc[i] =}\StringTok{ }\NormalTok{zi[}\DecValTok{2}\NormalTok{]}
\NormalTok{  \}}
  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{Uc=}\NormalTok{Uc,}\DataTypeTok{Vc=}\NormalTok{Vc) )}
\NormalTok{\}}

\CommentTok{#Newton Raphson update}
\CommentTok{# Compute first/second derives of complete data log likelihood}
\NormalTok{## score and fisher information}
\NormalTok{SF.mh <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(Vu,beta,Uc,Vc, D,X,subj)\{}
\NormalTok{  ## S/hessian matrix}
\NormalTok{  sid =}\StringTok{ }\KeywordTok{unique}\NormalTok{(subj);  n =}\StringTok{ }\KeywordTok{length}\NormalTok{(sid)}
\NormalTok{  p =}\StringTok{ }\KeywordTok{dim}\NormalTok{(X)[}\DecValTok{2}\NormalTok{]}
\NormalTok{  S =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, p)}
\NormalTok{  FI =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, p,p)}
\NormalTok{  sig2 =}\StringTok{ }\DecValTok{0}
  \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n)}
\NormalTok{    \{}
\NormalTok{    ij =}\StringTok{ }\KeywordTok{which}\NormalTok{(subj}\OperatorTok{==}\NormalTok{sid[i]);  ni =}\StringTok{ }\KeywordTok{length}\NormalTok{(ij)}
\NormalTok{    Xi =}\StringTok{ }\NormalTok{X[ij,,drop=}\OtherTok{FALSE}\NormalTok{]}
\NormalTok{    eta =}\StringTok{ }\NormalTok{Xi}\OperatorTok{%*%}\NormalTok{beta}
\NormalTok{    zi =}\StringTok{ }\KeywordTok{U.mh}\NormalTok{(D[ij],eta,Vu,Uc[i],Vc[i], }\DataTypeTok{B=}\FloatTok{5e3}\NormalTok{)[}\OperatorTok{-}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\FloatTok{1e3}\NormalTok{)]}
\NormalTok{    theta =}\StringTok{ }\KeywordTok{sapply}\NormalTok{(eta, }\ControlFlowTok{function}\NormalTok{(b0)  }\KeywordTok{mean}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{b0}\OperatorTok{-}\NormalTok{zi))) )}
\NormalTok{    theta2 =}\StringTok{ }\KeywordTok{sapply}\NormalTok{(eta, }\ControlFlowTok{function}\NormalTok{(b0) }\KeywordTok{mean}\NormalTok{(}\KeywordTok{exp}\NormalTok{(b0}\OperatorTok{+}\NormalTok{zi)}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(b0}\OperatorTok{+}\NormalTok{zi))}\OperatorTok{^}\DecValTok{2}\NormalTok{) )}
\NormalTok{    FI =}\StringTok{ }\NormalTok{FI }\OperatorTok{+}\StringTok{ }\KeywordTok{t}\NormalTok{(Xi)}\OperatorTok{%*%}\NormalTok{(theta2}\OperatorTok{*}\NormalTok{Xi)}
\NormalTok{    S =}\StringTok{ }\NormalTok{S}\OperatorTok{+}\KeywordTok{colSums}\NormalTok{((D[ij]}\OperatorTok{-}\NormalTok{theta)}\OperatorTok{*}\NormalTok{Xi)}
\NormalTok{    sig2 =}\StringTok{ }\NormalTok{sig2 }\OperatorTok{+}\StringTok{ }\KeywordTok{mean}\NormalTok{(zi}\OperatorTok{^}\DecValTok{2}\NormalTok{)}
\NormalTok{    \}}
  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{S=}\NormalTok{S, }\DataTypeTok{FI=}\NormalTok{FI, }\DataTypeTok{sig2=}\NormalTok{sig2}\OperatorTok{/}\NormalTok{n) )}
\NormalTok{\}}

\KeywordTok{library}\NormalTok{(lme4)}
\NormalTok{sid =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n, K)}
\NormalTok{a1 =}\StringTok{ }\KeywordTok{glmer}\NormalTok{(}\KeywordTok{c}\NormalTok{(D) }\OperatorTok{~}\StringTok{ }\NormalTok{Xs }\OperatorTok{+}\StringTok{ }\NormalTok{Z[sid] }\OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1}\OperatorTok{|}\NormalTok{sid), }\DataTypeTok{family=}\NormalTok{binomial)}
\NormalTok{## extract variance and fixed effects parameters; + mode/variance of (random effects|data)}
\NormalTok{Vu =}\StringTok{ }\NormalTok{(}\KeywordTok{getME}\NormalTok{(a1,}\StringTok{'theta'}\NormalTok{))}\OperatorTok{^}\DecValTok{2}\NormalTok{; beta =}\StringTok{ }\KeywordTok{fixef}\NormalTok{(a1); Um =}\StringTok{ }\KeywordTok{ranef}\NormalTok{(a1,}\DataTypeTok{condVar=}\OtherTok{TRUE}\NormalTok{)}
\NormalTok{D =}\StringTok{ }\KeywordTok{c}\NormalTok{(D); X =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\DecValTok{1}\NormalTok{,Xs,Z[sid]); subj =}\StringTok{ }\NormalTok{sid}
\NormalTok{Uc =}\StringTok{ }\KeywordTok{unlist}\NormalTok{(Um[[}\DecValTok{1}\NormalTok{]]); Vc =}\StringTok{ }\KeywordTok{c}\NormalTok{( }\KeywordTok{attr}\NormalTok{(Um[[}\DecValTok{1}\NormalTok{]], }\StringTok{'postVar'}\NormalTok{) )}
\ControlFlowTok{for}\NormalTok{(b }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{100}\NormalTok{)\{}
\NormalTok{  ## NR updates with MH sampling}
\NormalTok{  obj =}\StringTok{ }\KeywordTok{SF.mh}\NormalTok{(Vu,beta,Uc,Vc, D,X,subj)}
\NormalTok{  Vu =}\StringTok{ }\NormalTok{obj}\OperatorTok{$}\NormalTok{sig2}
\NormalTok{  tmp =}\StringTok{ }\KeywordTok{solve}\NormalTok{(obj}\OperatorTok{$}\NormalTok{FI,obj}\OperatorTok{$}\NormalTok{S)}
\NormalTok{  beta =}\StringTok{ }\NormalTok{beta }\OperatorTok{+}\StringTok{ }\NormalTok{tmp}
\NormalTok{  ## Proposal dist update}
\NormalTok{  tmp1 =}\StringTok{ }\KeywordTok{UV.mh}\NormalTok{(Vu,beta,Uc, D,X,subj)}
\NormalTok{  Uc =}\StringTok{ }\NormalTok{tmp1}\OperatorTok{$}\NormalTok{Uc; Vc =}\StringTok{ }\NormalTok{tmp1}\OperatorTok{$}\NormalTok{Vc}
  \KeywordTok{cat}\NormalTok{(b, }\StringTok{':'}\NormalTok{, tmp, }\StringTok{';'}\NormalTok{, obj}\OperatorTok{$}\NormalTok{S}\OperatorTok{/}\NormalTok{n, }\StringTok{'}\CharTok{\textbackslash{}n\textbackslash{}t}\StringTok{'}\NormalTok{, }\KeywordTok{sqrt}\NormalTok{(Vu), beta, }\StringTok{'}\CharTok{\textbackslash{}n}\StringTok{'}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{Important Examples with R
code}\label{important-examples-with-r-code}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Fitting mixed models with (temporal) correlations in R
\end{enumerate}

\url{https://bbolker.github.io/mixedmodels-misc/notes/corr_braindump.html}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Mixed effects logistic regression
\end{enumerate}

\url{https://stats.idre.ucla.edu/r/dae/mixed-effects-logistic-regression/}

\section{References}\label{references-1}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Data
\end{enumerate}

\url{http://www.michelecoscia.com/?page_id=379}

\chapter{Newton Raphson - Intercept}\label{newton-raphson---intercept}

Using the Newton Raphson, the following code calculates the basic
logistic model, without any random effects. As we can see, it produces
the same result as the R generic function of GLM.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y<-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{) ## observations}
\NormalTok{n=}\KeywordTok{length}\NormalTok{(y) }\CommentTok{# the number of observations}
\NormalTok{Expit<-}\ControlFlowTok{function}\NormalTok{(x)\{}\KeywordTok{exp}\NormalTok{(x)}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(x))\}}

\NormalTok{x_intercept<-}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,n)}
\NormalTok{x_intercept<-}\KeywordTok{as.matrix}\NormalTok{(x_intercept)}

\NormalTok{tolerance=}\FloatTok{1e-3}
\NormalTok{max_its=}\DecValTok{2000}\NormalTok{;iteration=}\DecValTok{1}\NormalTok{;difference=}\DecValTok{2}
\NormalTok{W<-}\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,n,n)}
\NormalTok{beta_old<-}\FloatTok{0.1}

\ControlFlowTok{while}\NormalTok{(difference}\OperatorTok{>}\NormalTok{tolerance }\OperatorTok{&}\StringTok{ }\NormalTok{iteration}\OperatorTok{<}\NormalTok{max_its)}
\NormalTok{  \{}
  \CommentTok{# The first order}
\NormalTok{  f_firstorder<-}\KeywordTok{t}\NormalTok{(x_intercept)}\OperatorTok{%*%}\NormalTok{(y}\OperatorTok{-}\KeywordTok{Expit}\NormalTok{(x_intercept}\OperatorTok{%*%}\NormalTok{beta_old))}
  
  \CommentTok{# The second order}
  \KeywordTok{diag}\NormalTok{(W) =}\StringTok{ }\KeywordTok{Expit}\NormalTok{(x_intercept}\OperatorTok{%*%}\NormalTok{beta_old)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{Expit}\NormalTok{(x_intercept}\OperatorTok{%*%}\NormalTok{beta_old))}
  \CommentTok{#print(Expit(x_intercept%*%beta_old)*(1-Expit(x_intercept%*%beta_old)))}
  
\NormalTok{  f_secondorder<-}\OperatorTok{-}\KeywordTok{t}\NormalTok{(x_intercept)}\OperatorTok{%*%}\NormalTok{W}\OperatorTok{%*%}\NormalTok{x_intercept}
  
  \CommentTok{# Calculate the beta_updated}
\NormalTok{  beta_updated=beta_old}\OperatorTok{-}\NormalTok{(}\KeywordTok{solve}\NormalTok{(f_secondorder)}\OperatorTok{%*%}\NormalTok{f_firstorder)}
  
\NormalTok{  difference=}\KeywordTok{max}\NormalTok{(}\KeywordTok{abs}\NormalTok{(beta_updated}\OperatorTok{-}\NormalTok{beta_old));}
  
\NormalTok{  iteration=iteration}\OperatorTok{+}\DecValTok{1}\NormalTok{;}
  
\NormalTok{  beta_old=beta_updated\}}

\NormalTok{beta_old}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           [,1]
## [1,] 0.4054651
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glm}\NormalTok{(y}\OperatorTok{~}\DecValTok{1}\NormalTok{, }\DataTypeTok{family=}\NormalTok{binomial)}\OperatorTok{$}\NormalTok{coefficients}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept) 
##   0.4054651
\end{verbatim}

\chapter{The Main One}\label{the-main-one}

\section{The Basic Idea}\label{the-basic-idea}

\[L(\beta,D|Y)=\int \prod_{i=1}^{n} f_{y_i|u}(y_i|b_i,\beta)f_{b_i}(b_i|D)db_i\]

Notations :

\(y\): Variable for the fixed effect

\(b\): Variable for the random effect

\(\beta\): Parameters for the fixed effect

\(D\): Parameters for the random effect

The dimension of the integral is equal to the levels of the random
factors (i.e., the number of observations).

\section{Model and R Code}\label{model-and-r-code}

Covarance Matrix for \(n\) observations:

\[V=\sigma^2 \begin{bmatrix} 1 & \rho & \rho^2 & ... & \rho^{n-1} & \rho^n \\ \rho & 1 & \rho & ... & \rho^{n-2}& \rho^{n-1}\\ \rho^2 & \rho & 1 & ... & \rho^{n-3}& \rho^{n-2} \\ ...\\ \rho^n & \rho^{n-1} & \rho^{n-2} & ... & \rho & 1 \end{bmatrix}\]

\[ \frac{\partial V}{\partial \rho}=\sigma^2 \begin{bmatrix} 0 & 1 & \rho & ... & \rho^{n-2} & \rho^{n-1} \\ 1 & 0 & 1 & ... & \rho^{n-3}& \rho^{n-2}\\ \rho & 1 & 0 & ... & \rho^{n-4}& \rho^{n-3} \\ ...\\ \rho^{n-1} & \rho^{n-2} & \rho^{n-3} & ... & 1 & 0 \end{bmatrix}\]

\[\frac{\partial V}{\partial \sigma^2}=\begin{bmatrix} 1 & \rho & \rho^2 & ... & \rho^{n-1} & \rho^n \\ \rho & 1 & \rho & ... & \rho^{n-2}& \rho^{n-1}\\ \rho^2 & \rho & 1 & ... & \rho^{n-3}& \rho^{n-2} \\ ...\\ \rho^n & \rho^{n-1} & \rho^{n-2} & ... & \rho & 1 \end{bmatrix}\]

The inverse matrix is as follows:

\[Q=V^{-1}=\frac{1}{\sigma^2(1-\rho)} \begin{bmatrix} 1 & -\rho & 0 & ... & 0 & 0 \\ -\rho & 1+\rho^2 & -\rho & ... & 0 & 0\\ 0 & -\rho & 1+\rho^2 & ... & 0 & 0 \\ ...\\ 0 & 0 & 0 & ... & 1+\rho^2 &-\rho\\ 0 & 0 & 0 & ... & -\rho & 1 \end{bmatrix}\]
\[ \frac{\partial V}{\partial \rho}=\sigma^2 \begin{bmatrix} 0 & 1 & \rho & \rho^2 ... & \rho^{n-2} & \rho^{n-1} \\ 1 & 0 & 1 & \rho  ... & \rho^{n-3}& \rho^{n-2}\\ \rho & 1 & 0 & 1 ... & \rho^{n-4}& \rho^{n-3} \\ ...\\ \rho^{n-1} & \rho^{n-2} & \rho^{n-3} & ... & 1 & 0 \end{bmatrix}\]

\[ V^{-1} \frac{\partial V}{\partial \rho} =\frac{1}{(1-\rho)} \begin{bmatrix} -\rho & 1  & 0 & 0... & 0 & 0 \\ 1 & -2\rho & 1 & 0... & 0& 0\\ 0 &  1& -2\rho & 1... & 0& 0 \\ ...\\ 0& 0& 0& 0 ... &-2\rho & 1\\ 0 & 0 & 0 & ... & 1 & -\rho \end{bmatrix}\]
\[V^{-1}=\frac{1}{\sigma^2(1-\rho)} \begin{bmatrix} 1 & -\rho & 0 & 0 ... & 0 & 0 \\ -\rho & 1+\rho^2 & -\rho & 0 ... & 0 & 0\\ 0 & -\rho & 1+\rho^2 & -\rho... & 0 & 0 \\ ...\\ 0 & 0 & 0 & ... & 1+\rho^2 &-\rho\\ 0 & 0 & 0 & ... & -\rho & 1 \end{bmatrix}\]

\[ V^{-1} \frac{\partial V}{\partial \rho}V^{-1} =\frac{1}{\sigma^2(1-\rho)^2} \begin{bmatrix} -2\rho & 1  & -\rho & 0... & 0 & 0 \\ 1+2\rho
^2& -4\rho-2 \rho^3 & 1+3\rho^2 & -\rho... & 0& 0\\ -\rho &  1+3\rho^2 & -4\rho-2 \rho^3 & 1+3\rho^2... & 0& 0 \\ ...\\ 0 & 0 & 0 & ...& -4 \rho -2 \rho^3 & 1+ 2 \rho^2\\ 0 & 0 & 0 & ... & 1+2\rho^2 & -2\rho \end{bmatrix}\]

\[N(-\sum_{j\neq k} Q_{kj}b_j^{(m)}Q_{kk}^{-1},Q_{kk}^{-1})\]
\[ln L(\beta, \theta; Y,b)=\ell=lnf_{Y|b}(Y|b,\beta)+lnf_b(b|\theta)\]

\[a^{(m+1)}=a^{(m)}+\tau(a^{(m)})^{-1} S(a^{(m)})\] Where,

\[\tau(a) = -E(\frac{\partial^2 \ell}{\partial \alpha \partial \alpha^{'}}|Y)\]

\[S(a) = E(\frac{\partial \ell}{\partial \alpha }|Y)\] Note that,
\(\alpha\) is a combination of two sets of parameters.

\[\alpha = \binom{\beta}{b} \]

\[\ell=\sum_{i=1}^{n}\{[y_i ln (\frac{e^{\beta^Tx_i+b_i}}{1+e^{\beta^Tx_i+b_i}}) + (1-y_i) ln(1-\frac{e^{\beta^Tx_i+b_i}}{1+e^{\beta^Tx_i+b_i}})]+lnf_b(b_i|\theta)\}\]

\[\frac{\partial lnf(Y|b, \beta)}{\partial \beta}=X^{'}(Y-E(Y|b))\]

\[\frac{\partial lnf(Y|b, \beta)}{\partial \beta \partial \beta^{'}}=-X^{'}(Y-E(Y|b))\]

\[\begin{aligned} \nabla \ell &= \sum_{i=1}^{n} [y_i \frac{1}{p(\beta ^T x_i+b_i)} \frac{\partial p(\beta ^T x_i+b_i)}{\partial (\beta ^T x_i+b_i)}\frac{\partial (\beta ^T x_i+b_i)}{\partial \beta}+(1-y_i) \frac{1}{1-p(\beta ^T x_i+b_i)}(-1)\frac{\partial p(\beta ^T x_i+b_i)}{\partial (\beta ^T x_i+b_i)}\frac{\partial (\beta ^T x_i+b_i)}{\partial \beta}] \\ &=\sum_{i=1}^{n} x_i^T[y_i-p(\beta ^T x_i+b_i)] \\ &= \sum_{i=1}^{n} x_i^T[y_i-\frac{e^{\beta^Tx_i+b_i}}{1+e^{\beta^Tx_i+b_i}}] \end{aligned}\]

The Newton Raphson algorithm needs the second order.

\[\begin{aligned} \nabla^2 \ell &=\frac{\partial \sum_{i=1}^{n} x_i^T[y_i-p(\beta ^T x_i+b_i)]}{\partial \beta} \\ &=-\sum_{i=1}^{n} x_i^T\frac{\partial p(\beta ^T x_i+b_i) }{\partial \beta}\\ &=-\sum_{i=1}^{n} x_i^T\frac{\partial p(\beta ^T x_i+b_i) }{\partial (\beta^Tx_i+b_i)} \frac{\partial (\beta^Tx_i+b_i)}{\partial \beta}\\ &=-\sum_{i=1}^{n} x_i^T p(\beta ^T x_i+b_i)(1-p(\beta ^T x_i+b_i))x_i \\ &=-\sum_{i=1}^{n} x_i^T \frac{e^{\beta^Tx_i+b_i}}{1+e^{\beta^Tx_i+b_i}}(1-\frac{e^{\beta^Tx_i+b_i}}{1+e^{\beta^Tx_i+b_i}})x_i \end{aligned}\]

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#install.packages("CVTuningCov")}
\KeywordTok{library}\NormalTok{(CVTuningCov) }\CommentTok{# Will be used to generate AR1 matrix}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{y<-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{) ## observations}

\NormalTok{n=}\KeywordTok{length}\NormalTok{(y) }\CommentTok{# the number of observations}

\CommentTok{#Establish the exp function}
\NormalTok{Expit<-}\ControlFlowTok{function}\NormalTok{(x)\{}\KeywordTok{exp}\NormalTok{(x)}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(x))\}}
\CommentTok{#Y: observations}
\CommentTok{#b: random effect}
\CommentTok{#beta_0:fixed effect->intercept (or, mean of Y)}

\NormalTok{log_pdf_function<-}\ControlFlowTok{function}\NormalTok{(Y,b,beta_}\DecValTok{0}\NormalTok{)}
\NormalTok{  \{mean_prob<-}\KeywordTok{Expit}\NormalTok{(beta_}\DecValTok{0}\OperatorTok{+}\NormalTok{b)}
  \KeywordTok{dbinom}\NormalTok{(Y,}\DecValTok{1}\NormalTok{,mean_prob,}\DataTypeTok{log =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{  \}}

\NormalTok{b_records<-}\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,n)  }\CommentTok{#Initial values for the random effect}
\NormalTok{rho_records<-}\FloatTok{0.5} \CommentTok{#Initial value for rho}
\NormalTok{sigma_recoards<-}\DecValTok{2}  \CommentTok{#Initial value for sigma}
\NormalTok{mean_}\DecValTok{0}\NormalTok{<-}\DecValTok{0} \CommentTok{# Initial mean value for normal distribution (of the random effect)}
\NormalTok{beta<-}\FloatTok{0.5} \CommentTok{# Initial value for the intercept of Y}


\NormalTok{f_random<-}\ControlFlowTok{function}\NormalTok{(sigma_recoards, rho_records,beta)}
\NormalTok{\{}
\NormalTok{co_matrix<-(sigma_recoards}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{*}\KeywordTok{AR1}\NormalTok{(n,rho_records) }\CommentTok{# covariance matrix}
\NormalTok{co_matrix_inverse<-}\KeywordTok{solve}\NormalTok{(co_matrix)  }\CommentTok{# inverse covariance matrix}


\ControlFlowTok{for}\NormalTok{ (k }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n)}
\NormalTok{ \{}
  \CommentTok{# Variance for the random effect}
\NormalTok{  sd_}\DecValTok{0}\NormalTok{<-}\DecValTok{1}\OperatorTok{/}\NormalTok{(co_matrix_inverse[k,k])}
  
  \CommentTok{# mean for the random effect}
  \ControlFlowTok{for}\NormalTok{(j }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n)}
\NormalTok{      \{ }\CommentTok{# Make sure that k is not equal to j, otherwise 0}
\NormalTok{        Q_kj<-}\KeywordTok{ifelse}\NormalTok{(j}\OperatorTok{!=}\NormalTok{k,co_matrix_inverse[k,j],}\DecValTok{0}\NormalTok{)}
        \CommentTok{# Calculate the mean for the random effect; sum of mean in a loop}
\NormalTok{        mean_}\DecValTok{0}\NormalTok{<-mean_}\DecValTok{0}\OperatorTok{-}\NormalTok{(Q_kj}\OperatorTok{/}\NormalTok{co_matrix_inverse[k,k])}\OperatorTok{*}\NormalTok{b_records[j]}
\NormalTok{      \}}
  
  \CommentTok{# Draw a random number from the normal distribution for the random effect}
\NormalTok{  b_candidate<-}\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{,mean_}\DecValTok{0}\NormalTok{,sd_}\DecValTok{0}\NormalTok{)}
  
\NormalTok{  current_lp<-}\KeywordTok{log_pdf_function}\NormalTok{(y[k],b_records[k],beta)}
\NormalTok{  candidate_lp<-}\KeywordTok{log_pdf_function}\NormalTok{(y[k],b_candidate,beta)}
  
\NormalTok{  Smaller_value<-}\KeywordTok{min}\NormalTok{(}\KeywordTok{exp}\NormalTok{(candidate_lp}\OperatorTok{-}\NormalTok{current_lp),}\DecValTok{1}\NormalTok{)}
  \CommentTok{# Draw a random number from the uniform distribution}
  
\NormalTok{  Random_probability<-}\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{)}
  
  \CommentTok{# Update b (i.e., random variable)}
\NormalTok{  b_records[k]<-}\KeywordTok{ifelse}\NormalTok{(Random_probability}\OperatorTok{<}\NormalTok{Smaller_value,b_candidate,b_records[k])}
\NormalTok{\}}

\KeywordTok{return}\NormalTok{(b_records)}
\NormalTok{\}}

\CommentTok{# Print result}
\NormalTok{b_records<-}\KeywordTok{f_random}\NormalTok{(}\DecValTok{1}\NormalTok{,}\FloatTok{0.8}\NormalTok{,}\FloatTok{0.3}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

In the following, I will try to add the random effect.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x_intercept<-}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,n)}
\NormalTok{x_intercept<-}\KeywordTok{as.matrix}\NormalTok{(x_intercept)}

\CommentTok{#We need to set random starting values.}

\NormalTok{tolerance=}\FloatTok{1e-3}
\NormalTok{max_its=}\DecValTok{2000}\NormalTok{;iteration=}\DecValTok{1}\NormalTok{;difference=}\DecValTok{2}
\NormalTok{W<-}\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,n,n)}
\NormalTok{beta_old<-}\FloatTok{0.4}

\ControlFlowTok{while}\NormalTok{(difference}\OperatorTok{>}\NormalTok{tolerance }\OperatorTok{&}\StringTok{ }\NormalTok{iteration}\OperatorTok{<}\NormalTok{max_its)}
\NormalTok{  \{}
\NormalTok{  b_records<-}\KeywordTok{f_random}\NormalTok{(}\DecValTok{2}\NormalTok{,}\FloatTok{0.9}\NormalTok{,beta_old)}
  \KeywordTok{print}\NormalTok{(}\StringTok{"first"}\NormalTok{)}
  \KeywordTok{print}\NormalTok{(beta_old)}
  \KeywordTok{print}\NormalTok{(b_records)}
  \CommentTok{# The first order}
\NormalTok{  f_firstorder<-}\KeywordTok{t}\NormalTok{(x_intercept)}\OperatorTok{%*%}\NormalTok{(y}\OperatorTok{-}\KeywordTok{Expit}\NormalTok{(x_intercept}\OperatorTok{%*%}\NormalTok{beta_old}\OperatorTok{+}\NormalTok{b_records))}
  \KeywordTok{print}\NormalTok{(f_firstorder)}
  \CommentTok{# The second order}
  \KeywordTok{diag}\NormalTok{(W) =}\StringTok{ }\KeywordTok{Expit}\NormalTok{(x_intercept}\OperatorTok{%*%}\NormalTok{beta_old}\OperatorTok{+}\NormalTok{b_records)}\OperatorTok{*}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{Expit}\NormalTok{(x_intercept}\OperatorTok{%*%}\NormalTok{beta_old}\OperatorTok{+}\NormalTok{b_records))}
  
\NormalTok{  f_secondorder<-}\OperatorTok{-}\KeywordTok{t}\NormalTok{(x_intercept)}\OperatorTok{%*%}\NormalTok{W}\OperatorTok{%*%}\NormalTok{x_intercept}
  
  \CommentTok{# Calculate the beta_updated}
\NormalTok{  beta_updated=beta_old}\OperatorTok{-}\NormalTok{(}\KeywordTok{solve}\NormalTok{(f_secondorder)}\OperatorTok{%*%}\NormalTok{f_firstorder)}
  
\NormalTok{  difference=}\KeywordTok{max}\NormalTok{(}\KeywordTok{abs}\NormalTok{(beta_updated}\OperatorTok{-}\NormalTok{beta_old));}
  
\NormalTok{  iteration=iteration}\OperatorTok{+}\DecValTok{1}\NormalTok{;}
  
\NormalTok{  beta_old=beta_updated}
\NormalTok{  \}}

\NormalTok{beta_old}
\end{Highlighting}
\end{Shaded}

\section{glmmTMB package}\label{glmmtmb-package}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# https://becarioprecario.bitbucket.io/inla-gitbook/ch-intro.html}
\CommentTok{#https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html}
\CommentTok{#install.packages("glmmTMB")}
\KeywordTok{library}\NormalTok{(glmmTMB)}

\NormalTok{times <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n)}
\KeywordTok{levels}\NormalTok{(times)}
\NormalTok{group <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,n))}
\NormalTok{dat0 <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(y,times,group)}

\KeywordTok{glmmTMB}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\KeywordTok{ar1}\NormalTok{(times }\OperatorTok{+}\StringTok{ }\DecValTok{0} \OperatorTok{|}\StringTok{ }\NormalTok{group), }\DataTypeTok{data=}\NormalTok{dat0)}
\end{Highlighting}
\end{Shaded}

\bibliography{book.bib,packages.bib}

\end{document}
